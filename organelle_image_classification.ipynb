{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organelle image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "1. efficientnetv2\n",
    "2. Introduce regularization techniques like dropout or batch normalization to prevent overfitting. Dropout layers can help reduce interdependency among neurons by randomly dropping some during training. Batch normalization helps in stabilizing and accelerating the training process.\n",
    "3. over/undersampling\n",
    "4. show batch, show NN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This project aims to reach protein classification through advanced image analysis techniques. The primary objective is to create a machine learning model capable of predicting the presence of specific proteins within a given image, addressing the complexity of a multi-label classification challenge. The metric of choice for assessing model performance is the mean F1-score, ensuring precision and recall are both accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_data_dir = \"./train\"\n",
    "train_csv = \"./train.csv\"\n",
    "\n",
    "test_data_dir = \"./test\"\n",
    "test_csv = \"./sub.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file containing the train labels\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the label dictionary\n",
    "labels = {\n",
    "    0: \"Mitochondria\",\n",
    "    1: \"Nuclear bodies\",\n",
    "    2: \"Nucleoli\",\n",
    "    3: \"Golgi apparatus\",\n",
    "    4: \"Nucleoplasm\",\n",
    "    5: \"Nucleoli fibrillar center\",\n",
    "    6: \"Cytosol\",\n",
    "    7: \"Plasma membrane\",\n",
    "    8: \"Centrosome\",\n",
    "    9: \"Nuclear speckles\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12874</td>\n",
       "      <td>1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095</td>\n",
       "      <td>2 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Label\n",
       "0  12874   1 4\n",
       "1  21466     0\n",
       "2   3610     4\n",
       "3   2095   2 4\n",
       "4  28909     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are correctly loaded as a dataframe, each image has a series of associated labels, delimited by spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check class distribution\n",
    "\n",
    "label_counts = {}\n",
    "flat_label_list =[]\n",
    "for values in train_df['Label']:\n",
    "    label_list = values.split()\n",
    "    for label in label_list:\n",
    "        flat_label_list.append(label)\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "\n",
    "\n",
    "sorted_label_counts = {k: v for k, v in sorted(label_counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_label_counts.keys(), sorted_label_counts.values())\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is noticable class imbalance, 4 and 6 (Golgi apparatus, Nucleoplasm) have a much larger occurrence than the other classes.\n",
    "\n",
    "SOLUTIONS:\n",
    "1) Weights will be calculated and a weighted loss function will be used that assigns higher weights to minority class samples during training.\n",
    "2) Oversampling- and undersampling techniques help to handle imbalanced classes effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.3986194477791116, 1: 1.6294405594405594, 2: 1.1506666666666667, 3: 1.4936538461538462, 4: 0.3203767358724048, 5: 2.7125727590221187, 6: 0.5094228246611281, 7: 1.1251086431675519, 8: 2.787200956937799, 9: 2.3139026812313803}\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels from the dataset\n",
    "unique_labels = set(str(key) for key in labels.keys())\n",
    "unique_labels = sorted(list(unique_labels))\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=unique_labels, y=  flat_label_list)\n",
    "weights_dict = {i:class_weights[i] for i in range(10)}\n",
    "print(\"Class weights:\", weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, more abundant classes 4 and 6 now carry lower weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Information:\n",
      "Image Size: (128, 128)\n",
      "Image Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "# Explore image characteristics\n",
    "sample_image = Image.open('./train/0.png')\n",
    "\n",
    "print(\"Sample Image Information:\")\n",
    "print(f\"Image Size: {sample_image.size}\")\n",
    "print(f\"Image Mode: {sample_image.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing labels: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_labels = train_df['Label'].isnull().sum()\n",
    "print(\"Number of missing labels:\", missing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a multi-label classification problem, images can have more than 1 label. In order to transform the labels to a tensor that can be used for training, we can encode them to the format of a tensor, using a one-hot-encoding.\n",
    "def encode_label(label: str):\n",
    "    # create tensor of length 10 for the one-hot-ecoding\n",
    "    target = torch.zeros(10)\n",
    "    # now iterate over the classes in the string and set the respective 0's to 1's\n",
    "    for l in str(label).split(\" \"):\n",
    "        target[int(l)] = 1.0\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to decode the encoded labels back to its original format\n",
    "def decode_target(\n",
    "    target: torch.Tensor, text_labels: bool = False, threshold: float = 0.5\n",
    "):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if x >= threshold:\n",
    "            if text_labels:\n",
    "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per channel: [0.07819786874680719, 0.05209000149719703, 0.05402339364832606]\n",
      "Standard deviation per channel: [0.11591775167397261, 0.07654528936568694, 0.13421668103375917]\n"
     ]
    }
   ],
   "source": [
    "# To normalize the data, we need to calculate the means and stdevs per channel for the images\n",
    "\n",
    "# Initialize lists to store channel-wise mean and standard deviation\n",
    "mean_per_channel = [0.0, 0.0, 0.0]\n",
    "std_per_channel = [0.0, 0.0, 0.0]\n",
    "\n",
    "# Iterate over all images in the dataset directory\n",
    "count = 0\n",
    "for filename in os.listdir(train_data_dir):\n",
    "    img = Image.open(os.path.join(train_data_dir, filename))\n",
    "    img = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    \n",
    "    # Calculate per-channel mean\n",
    "    mean_per_channel[0] += np.mean(img[:, :, 0])\n",
    "    mean_per_channel[1] += np.mean(img[:, :, 1])\n",
    "    mean_per_channel[2] += np.mean(img[:, :, 2])\n",
    "    \n",
    "    # Calculate per-channel standard deviation\n",
    "    std_per_channel[0] += np.std(img[:, :, 0])\n",
    "    std_per_channel[1] += np.std(img[:, :, 1])\n",
    "    std_per_channel[2] += np.std(img[:, :, 2])\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "# Calculate the mean and standard deviation across all images\n",
    "total_images = len(os.listdir(train_data_dir))\n",
    "mean_per_channel = [m / total_images for m in mean_per_channel]\n",
    "std_per_channel = [s / total_images for s in std_per_channel]\n",
    "\n",
    "print(\"Mean per channel:\", mean_per_channel)\n",
    "print(\"Standard deviation per channel:\", std_per_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not dealing with everyday images but fluorescence microscopy. In these images, the RGB values behave different than regular. We will normalize the values based on the means and stdevs per channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a PyTorchDataset that will ease the training process and can be used later for the DataLoader:\n",
    "\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_dir='./train', transform=None, mode='train'):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode  # 'train' or 'test'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            img_name = os.path.join(self.data_dir, str(self.data.iloc[idx, 0]) + '.png')\n",
    "            image = Image.open(img_name)\n",
    "            label = encode_label(self.data.iloc[idx, 1])\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "        elif self.mode == 'test':\n",
    "            img_name = os.path.join(self.data_dir, str(self.data.iloc[idx, 0]) + '.png')\n",
    "            image = Image.open(img_name)\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, self.data.iloc[idx, 0]  # Return image name for test mode\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Use 'train' or 'test'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128 pixels if needed\n",
    "    #transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
    "    #transforms.RandomVerticalFlip(),  # Randomly flip images vertically\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_per_channel, std=std_per_channel)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rotations and horizontal/vertical flips don't affect performance as the histological slides are not fixated in a certain orientation before imaging. All organelles are represented in a random rotation already.\n",
    "- Cropping is unnecesary as the images are focused on the organelles of interest. There is no background noise to remove.\n",
    "# - random flips for increating variation --> reduces overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_df))\n",
    "val_size = len(train_df) - train_size\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(train_df, test_size=val_size)\n",
    "\n",
    "train_loader = DataLoader(ProteinDataset(train_dataset, transform=transforms_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(ProteinDataset(val_dataset, transform=transforms_train), batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class_weights dictionary to a tensor\n",
    "class_weights_tensor = torch.tensor([class_weights[i] for i in range(len(class_weights))], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProteinCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            32 * 32 * 32, 256\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            256, 10\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(\n",
    "            -1, 32 * 32 * 32\n",
    "        )\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProteinCNN()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(weight=class_weights_tensor) # take into account the class_weights to battle the class imbalance\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 TINYVGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyVGG, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # Adjusted linear layer based on the output size after the final pooling\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 32)  # Change to 32\n",
    "        self.fc2 = nn.Linear(32, 10)  # 10 output classes\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        # Ensure the output size matches the expected label size\n",
    "        x = x.view(-1, 128 * 4 * 4)  # Adjust the shape to match the flattened output size\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TinyVGG model\n",
    "model = TinyVGG()\n",
    "\n",
    "\n",
    "# Define the loss function (BCEWithLogitsLoss) and the optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not dealing with everyday images but fluorescence microscopy. In these images, the RGB values behave different than regular. We will normalize the values based on the means and stdevs per channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinTinyVGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProteinTinyVGG, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            64 * 8 * 8, 256\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            256, 10\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Add dropout with probability 0.5\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)  # Apply dropout after the activation function\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)  # Apply dropout after the activation function\n",
    "        x = self.pool(self.relu(self.conv4(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.4631205511557591, Validation Loss: 0.5215137155400109\n",
      "Epoch 2/10, Training Loss: 0.4377297099534567, Validation Loss: 0.4609956019317981\n",
      "Epoch 3/10, Training Loss: 0.4215284309603951, Validation Loss: 0.4379791933851144\n",
      "Epoch 4/10, Training Loss: 0.4068453297986613, Validation Loss: 0.4323867107789541\n",
      "Epoch 5/10, Training Loss: 0.3934876713659856, Validation Loss: 0.40320543898749595\n",
      "Epoch 6/10, Training Loss: 0.38434632366353816, Validation Loss: 0.3851793939919816\n",
      "Epoch 7/10, Training Loss: 0.37415660867443334, Validation Loss: 0.38320785484363123\n",
      "Epoch 8/10, Training Loss: 0.36380992547258156, Validation Loss: 0.36662522388487745\n",
      "Epoch 9/10, Training Loss: 0.3564735824798609, Validation Loss: 0.38642563340590175\n",
      "Epoch 10/10, Training Loss: 0.3443231653857541, Validation Loss: 0.3613057234852584\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TinyVGG model\n",
    "model = ProteinTinyVGG()\n",
    "\n",
    "\n",
    "# Define the loss function (BCEWithLogitsLoss) and the optimizer\n",
    "criterion = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data\n",
    "    print(labels.size())\n",
    "    outputs = model(inputs)\n",
    "    print(outputs.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 RESNET-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to fit ResNet-50 input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.07819786874680719, 0.05209000149719703, 0.05402339364832606],\n",
    "                         std=[0.11591775167397261, 0.07654528936568694, 0.13421668103375917])\n",
    "])\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(train_df))\n",
    "val_size = len(train_df) - train_size\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(train_df, test_size=val_size)\n",
    "\n",
    "train_loader = DataLoader(ProteinDataset(train_dataset, transform=transform), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(ProteinDataset(val_dataset, transform=transform), batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize the pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Freeze all the layers in the pre-trained model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modify the last fully connected layer to match the number of classes in your dataset\n",
    "num_classes = 10\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Define loss function, optimizer, and learning rate\n",
    "criterion = nn.BCEWithLogitsLoss()  # Assuming you're using a binary cross-entropy loss for multi-label classification\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold to convert probabilities to binary predictions\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs > threshold).float()\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average=None)\n",
    "recall = recall_score(true_labels, predicted_labels, average=None)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold to convert probabilities to binary predictions\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs > threshold).float()\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Convert lists to numpy arrays for evaluation\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average=None)\n",
    "recall = recall_score(true_labels, predicted_labels, average=None)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8331148/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# Define the model architecture using pre-trained DenseNet\n",
    "class ProteinDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ProteinDenseNet, self).__init__()\n",
    "        self.densenet = models.densenet121(pretrained=True)\n",
    "        # Modify the last fully connected layer to output the number of classes\n",
    "        num_features = self.densenet.classifier.in_features\n",
    "        self.densenet.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.Sigmoid()  # For multi-label classification\n",
    "        )\n",
    "# Densenet already has dropout layers so adding extra ones is unncessary\n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxvp/anaconda3/envs/ml_course_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/mxvp/anaconda3/envs/ml_course_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = ProteinDenseNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "ProteinDenseNet                               --\n",
       "DenseNet: 1-1                               --\n",
       "    Sequential: 2-1                        --\n",
       "        Conv2d: 3-1                       9,408\n",
       "        BatchNorm2d: 3-2                  128\n",
       "        ReLU: 3-3                         --\n",
       "        MaxPool2d: 3-4                    --\n",
       "        _DenseBlock: 3-5                  335,040\n",
       "        _Transition: 3-6                  33,280\n",
       "        _DenseBlock: 3-7                  919,680\n",
       "        _Transition: 3-8                  132,096\n",
       "        _DenseBlock: 3-9                  2,837,760\n",
       "        _Transition: 3-10                 526,336\n",
       "        _DenseBlock: 3-11                 2,158,080\n",
       "        BatchNorm2d: 3-12                 2,048\n",
       "    Sequential: 2-2                        --\n",
       "        Linear: 3-13                      524,800\n",
       "        ReLU: 3-14                        --\n",
       "        Linear: 3-15                      5,130\n",
       "        Sigmoid: 3-16                     --\n",
       "======================================================================\n",
       "Total params: 7,483,786\n",
       "Trainable params: 7,483,786\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the criterion and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you have your data loaders set up as train_loader and val_loader\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.9042884990253411\n",
      "Precision for each label: [0.85148515 0.5        0.86666667 0.675      0.79534884 0.60824742\n",
      " 0.6974026  0.71296296 0.62068966 0.71264368]\n",
      "Recall for each label: [0.50439883 0.38095238 0.42523364 0.53289474 0.83240612 0.33146067\n",
      " 0.60067114 0.36406619 0.20571429 0.3315508 ]\n",
      "F1-score for each label: [0.6335175  0.43243243 0.57053292 0.59558824 0.81345566 0.42909091\n",
      " 0.64543269 0.48200313 0.30901288 0.45255474]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "threshold = 0.5  # Define a threshold for prediction\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold to convert probabilities to binary predictions\n",
    "        predicted = (outputs > threshold).float()\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "        total += labels.size(0) * labels.size(1)  # Total number of elements in the batch\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on validation set: {accuracy}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each label separately\n",
    "precision = precision_score(true_labels, predicted_labels, average=None)\n",
    "recall = recall_score(true_labels, predicted_labels, average=None)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Print or use the calculated scores as needed\n",
    "print(\"Precision for each label:\", precision)\n",
    "print(\"Recall for each label:\", recall)\n",
    "print(\"F1-score for each label:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [16, 32, 64]\n",
    "    # Add other hyperparameters to tune\n",
    "}\n",
    "\n",
    "# Define your model creation as a function\n",
    "def create_model(lr, batch_size):\n",
    "    model = ProteinTinyVGGWithDropout()  # Modify this line if using a different model\n",
    "    criterion = nn.BCEWithLogitsLoss(weight=class_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    return model, criterion, optimizer\n",
    "\n",
    "# Create an instance of the model\n",
    "model = create_model()\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='f1_weighted')\n",
    "\n",
    "# Fit the model with the grid search\n",
    "grid_search.fit(train_loader)\n",
    "\n",
    "# Get the best parameters and their performance\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best F1 Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the test set\n",
    "\n",
    "test_dataset = ProteinDataset(test_df, data_dir=test_data_dir, transform=transforms_train, mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test images\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, img_names in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold for binary predictions\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs > threshold).squeeze().cpu().numpy().astype(int)\n",
    "        \n",
    "        # Convert predictions to label format\n",
    "        predicted_labels = \" \".join([str(i) for i in np.where(predicted == 1)[0]])\n",
    "\n",
    "        # Append image names and predicted labels to list\n",
    "        predictions.append((img_names[0].item(), predicted_labels))\n",
    "\n",
    "# Write predictions to sub.csv\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"Image\", \"Label\"])\n",
    "submission_df.to_csv(\"sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDENDUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model checkpoint\n",
    "# Save the model state and optimizer state\n",
    "torch.save({\n",
    "    'epoch': num_epochs,  # Current epoch count\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    # Add other necessary information\n",
    "}, 'checkpoint.pth')  # Save the checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mxvp/anaconda3/envs/ml_course_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/mxvp/anaconda3/envs/ml_course_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/10, Training Loss: 0.221843211333473, Validation Loss: 0.2621154416467726\n",
      "Epoch 13/10, Training Loss: 0.21818800022849788, Validation Loss: 0.24566869007557937\n",
      "Epoch 14/10, Training Loss: 0.21435287223233804, Validation Loss: 0.24995970833547337\n",
      "Epoch 15/10, Training Loss: 0.21023100651316828, Validation Loss: 0.24797847774839893\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# additional training\n",
    "\n",
    "# Load the model\n",
    "model = ProteinDenseNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch_start = checkpoint['epoch'] + 1  # Start from the next epoch\n",
    "\n",
    "# Continue training for additional epochs\n",
    "num_epochs_to_continue = 4\n",
    "for epoch in range(epoch_start, epoch_start + num_epochs_to_continue):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAIjCAYAAAAN/63DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABCjElEQVR4nO3deXxN1/7/8feREU0OEZk0klBTJdRU023NIabbmmlTVKO3Wq6ig7qG3ttWR9Wi4zWVqLa3qFYbFTG0RQU3JajqLUqbiBKJoBHs3x9+zrdHkiISJ7Fez8djPx45a6+992fZR/u2ss4+NsuyLAEAAACGKOfqAgAAAIDriQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAzgsubNmyebzSabzaa1a9fm229Zlm655RbZbDa1bdu2SNeYMmWKbDabU9sbb7yhefPm5eu7f/9+2Wy2Avddau3atYXWfTkXx71ly5arPvZy59y/f/8V9d++fbuGDh2qiIgIeXt766abblLjxo314osv6tixY45+bdu2LfKffUm6+L6x2Wxyc3NT5cqV1bBhQz344IPatGlTvv5Xc2//aNGiRZo+ffpVHVPQtS6+D3/77berOtef2bVrl6ZMmVLgPR8yZIjCw8OL7VoArgwBGMAV8/Hx0ezZs/O1r1u3Tv/73//k4+NTrNcrLAAHBwdr48aN6tatW7Fer7R599131aRJEyUnJ+uxxx5TQkKCli5dqr59++qtt97SsGHDXF3iFenTp482btyor7/+WosXL9Z9992nTZs2qWXLlvr73//u1Leo97YoAfh6vY927dqlp59+usAAPHHiRC1durRErw8gP3dXFwCg7Ojfv7/i4+M1a9Ys+fr6Otpnz56tli1bKjs7+7rU4eXlpRYtWlyXa7nKxo0b9dBDD6lTp05atmyZvLy8HPs6deqksWPHKiEhwYUVXrnAwECn+9W5c2eNHj1aw4cP1+uvv666devqoYceknR97u25c+d09uzZUvE+qlmzpkuvD5iKGWAAV2zgwIGSpPfff9/RlpWVpY8//lj3339/vv6FLT+4kl9zh4eHa+fOnVq3bp3jV+gXf1Vc1F+TX7RlyxYNGDBA4eHhKl++vMLDwzVw4EAdOHCgwP6ZmZkaOnSo/Pz8VLFiRfXo0UM//fRTvn6JiYnq0KGDfH19VaFCBbVu3VqrV68uUo3PPfecbDab3nnnHafwe5Gnp6d69uz5p+d4+umn1bx5c/n5+cnX11eNGzfW7NmzZVmWU7+kpCS1bdtWVapUUfny5VW9enX17t1bp06dcvR588031bBhQ910003y8fFR3bp19dRTTxVpbJLk5uammTNnyt/fXy+99JKjvaB7e+TIEQ0fPlyhoaHy8vJS1apV1bp1ayUmJkq6sPxjxYoVOnDggNOSiz+e78UXX9QzzzyjiIgIeXl5ac2aNX/6Pjp48KB69eolX19f2e123XvvvTpy5IhTH5vNpilTpuQ7Njw8XEOGDJF0YclL3759JUnt2rVz1HbxmgUtgfj99981fvx4RUREyNPTU9WqVdPDDz+s48eP57tO9+7dlZCQoMaNG6t8+fKqW7eu5syZc5k/fQAEYABXzNfXV3369HH6H+z777+vcuXKqX///sV6raVLl6pGjRpq1KiRNm7cqI0bNxbbr4r379+vOnXqaPr06Vq5cqVeeOEFpaWlqVmzZgWu/Rw2bJjKlSvn+DX75s2b1bZtW6dAsnDhQkVHR8vX11fz58/Xhx9+KD8/P3Xu3PmqQ/C5c+eUlJSkJk2aKDQ09JrG+eCDD+rDDz/UkiVL1KtXL40cOVL/+te/nPp069ZNnp6emjNnjhISEvT888+rYsWKOnPmjCRp8eLFGjFihNq0aaOlS5dq2bJlevTRR3Xy5Mki1yZJ5cuXV8eOHbVv3z4dOnSo0H6xsbFatmyZJk2apC+//FL//ve/1bFjRx09elTShaUyrVu3VlBQkOO9snHjRqdzvP7660pKStLLL7+sL774QnXr1v3T2u6++27dcsst+s9//qMpU6Zo2bJl6ty5s/Ly8q5qjN26ddNzzz0nSZo1a5ajtsKWXViWpbvuuksvv/yyYmNjtWLFCo0ZM0bz589X+/btlZub69T/u+++09ixY/Xoo4/qk08+UYMGDTRs2DCtX7/+quoETMMSCABX5f7771e7du20c+dO1a9fX3PmzFHfvn2Lff1vo0aNVL58efn6+hb7r6n79OmjPn36OF6fO3dO3bt3V2BgoBYtWqRRo0Y59W/atKnT2uf69eurdevWmjVrliZMmKBTp07p73//u7p37+4U0rt27arGjRvrqaee0rfffnvF9f322286deqUIiIirmGU0ty5cx0/nz9/Xm3btpVlWXrttdc0ceJE2Ww2bd26Vb///rteeuklNWzY0NF/0KBBjp+/+eYbVapUSa+//rqjrUOHDtdU20VhYWGSpF9//VU333xzgX2++eYbPfDAA4qLi3O0/fWvf3X8fOutt6pSpUp/uqTB29tbK1eulIeHh6Ptzz6I2KtXL7344ouSpOjoaAUGBuqee+7Rhx9+qHvuueeKx1e1alXVqlXLUefl3stffvmlVq5cqRdffFGPPfaYpAtLXkJDQ9W/f3+99957Tn8Ov/32m7755htVr15dknTnnXdq9erVWrRoke68884rrhMwDTPAAK5KmzZtVLNmTc2ZM0c7duxQcnJygcsfrrezZ886bZf+mv+PcnJy9MQTT+iWW26Ru7u73N3dddNNN+nkyZPavXt3vv6XBp5WrVopLCxMa9askSRt2LBBx44d0+DBg51qOH/+vLp06aLk5ORrni0tiqSkJHXs2FF2u11ubm7y8PDQpEmTdPToUWVkZEiSbrvtNnl6emr48OGaP39+gUs7br/9dh0/flwDBw7UJ598UqxPSPiz+/TH68+bN0/PPPOMNm3adNWzsJLUs2dPp/B7OZfe8379+snd3d1xz0tKUlKSJDmWUFzUt29fVaxYMd9vE2677TZH+JUuBP3atWsXupwHwAUEYABXxWazaejQoVq4cKHeeust1a5dW3fccYdLa9q/f788PDyctnXr1hXaf9CgQZo5c6YeeOABrVy5Ups3b1ZycrKqVq2q06dP5+sfFBRUYNvFX8EfPnxY0oWZ5UvreOGFF2RZltMjyy7H399fFSpU0L59+674mEtt3rxZ0dHRki48TeKbb75RcnKyJkyYIEmOcdasWVOJiYkKCAjQww8/rJo1a6pmzZp67bXXHOeKjY3VnDlzdODAAfXu3VsBAQFq3ry5Vq1aVeT6LroY1EJCQgrt88EHH2jw4MH697//rZYtW8rPz0/33Xef0tPTr/g6wcHBV1XXpffc3d1dVapUcdzzknL06FG5u7uratWqTu02m83pPXdRlSpV8p3Dy8urwPcxgP/DEggAV23IkCGaNGmS3nrrLT377LOF9vP29pakfOsWi3MGUboQnpKTk53a6tSpU2DfrKwsffbZZ5o8ebKefPJJR3tubm6hIbWgoJWenq5bbrlF0oXAKkkzZswo9FfcgYGBlx/I/+fm5qYOHTroiy++0KFDhwpdGvBnFi9eLA8PD3322WeO+yBJy5Yty9f3jjvu0B133KFz585py5YtmjFjhkaPHq3AwEANGDBAkjR06FANHTpUJ0+e1Pr16zV58mR1795dP/zwg2MZw9U6ffq0EhMTVbNmzT8do7+/v6ZPn67p06fr559/1vLly/Xkk08qIyPjip+Ecekzpi8nPT1d1apVc7w+e/asjh496hQ4vby88r23JV1TSK5SpYrOnj2rI0eOOIVgy7KUnp6uZs2aFfncAP4PM8AArlq1atX02GOPqUePHho8eHCh/S5+un379u1O7cuXL7+i61zpTJanp6eaNm3qtBW2Jtlms8myrHxPVvj3v/+tc+fOFXhMfHy80+sNGzbowIEDji+eaN26tSpVqqRdu3blq+Pi5unpeQUj/j/jx4+XZVmKi4tzfBjtj/Ly8vTpp58WerzNZpO7u7vc3NwcbadPn9aCBQsKPcbNzU3NmzfXrFmzJEnbtm3L16dixYqKiYnRhAkTdObMGe3cufNqhuVw7tw5PfLIIzp69KieeOKJKz6uevXqeuSRR9SpUyen+op71vPSe/7hhx/q7NmzTl82Eh4enu+9nZSUpJycHKe2i++1K6nv4trqhQsXOrV//PHHOnnyZLGtvQZMxwwwgCJ5/vnnL9snKChIHTt21NSpU1W5cmWFhYVp9erVWrJkyRVdIyoqSosXL9YHH3ygGjVqyNvbW1FRUddUt6+vr+6880699NJL8vf3V3h4uNatW6fZs2erUqVKBR6zZcsWPfDAA+rbt68OHjyoCRMmqFq1ahoxYoQk6aabbtKMGTM0ePBgHTt2TH369FFAQICOHDmi7777TkeOHNGbb755VXW2bNlSb775pkaMGKEmTZrooYceUv369ZWXl6f//ve/eueddxQZGakePXoUeHy3bt00bdo0DRo0SMOHD9fRo0f18ssv5wv+b731lpKSktStWzdVr15dv//+u+MpHx07dpQkxcXFqXz58mrdurWCg4OVnp6uqVOnym63X9GM5OHDh7Vp0yZZlqUTJ04oNTVV7733nr777js9+uijTh/qulRWVpbatWunQYMGqW7duvLx8VFycrISEhLUq1cvR7+oqCgtWbJEb775ppo0aaJy5cqpadOml62tMEuWLJG7u7s6deqknTt3auLEiWrYsKH69evn6BMbG6uJEydq0qRJatOmjXbt2qWZM2fKbrc7nSsyMlKS9M4778jHx0fe3t6KiIgocPlCp06d1LlzZz3xxBPKzs5W69attX37dk2ePFmNGjVSbGxskccE4A8sALiMuXPnWpKs5OTkP+1Xv359q02bNk5taWlpVp8+fSw/Pz/Lbrdb9957r7VlyxZLkjV37lxHv8mTJ1uX/idp//79VnR0tOXj42NJssLCwizLsqx9+/blO74wa9assSRZa9ascbQdOnTI6t27t1W5cmXLx8fH6tKli5WammqFhYVZgwcPzjfuL7/80oqNjbUqVapklS9f3uratau1d+/efNdat26d1a1bN8vPz8/y8PCwqlWrZnXr1s366KOP8p1z3759l63dsiwrJSXFGjx4sFW9enXL09PTqlixotWoUSNr0qRJVkZGhqNfmzZt8v3Zz5kzx6pTp47l5eVl1ahRw5o6dao1e/Zsp+tv3LjRuvvuu62wsDDLy8vLqlKlitWmTRtr+fLljvPMnz/fateunRUYGGh5enpaISEhVr9+/azt27dftn5Jjq1cuXKWr6+vFRUVZQ0fPtzauHFjvv6X3tvff//d+tvf/mY1aNDA8vX1tcqXL2/VqVPHmjx5snXy5EnHcceOHbP69OljVapUybLZbI730sXzvfTSS5e9lmX93/tw69atVo8ePaybbrrJ8vHxsQYOHGgdPnzY6fjc3Fzr8ccft0JDQ63y5ctbbdq0sVJSUvK9jyzLsqZPn25FRERYbm5uTtccPHiw43190enTp60nnnjCCgsLszw8PKzg4GDroYcesjIzM536hYWFWd26dcs3roLeCwCc2SzrCj6CCwAAANwgWAMMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARuGLMK7Q+fPn9euvv8rHx+eqv1ITAAAAJc/6/1+4ExISonLlCp/nJQBfoV9//VWhoaGuLgMAAACXcfDgQd18882F7icAXyEfHx9JF/5AfX19XVwNAAAALpWdna3Q0FBHbisMAfgKXVz24OvrSwAGAAAoxS63XJUPwQEAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKO4u7oAAChLwp9c4eoSimT/891cXQIAlBrMAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjuDQAr1+/Xj169FBISIhsNpuWLVvmtN9msxW4vfTSS44+bdu2zbd/wIABTufJzMxUbGys7Ha77Ha7YmNjdfz48eswQgAAAJQ2Lg3AJ0+eVMOGDTVz5swC96elpTltc+bMkc1mU+/evZ36xcXFOfV7++23nfYPGjRIKSkpSkhIUEJCglJSUhQbG1ti4wIAAEDp5e7Ki8fExCgmJqbQ/UFBQU6vP/nkE7Vr1041atRwaq9QoUK+vhft3r1bCQkJ2rRpk5o3by5Jevfdd9WyZUvt2bNHderUKfC43Nxc5ebmOl5nZ2df0ZgAAABQupWZNcCHDx/WihUrNGzYsHz74uPj5e/vr/r162vcuHE6ceKEY9/GjRtlt9sd4VeSWrRoIbvdrg0bNhR6valTpzqWTNjtdoWGhhbvgAAAAOASLp0Bvhrz58+Xj4+PevXq5dR+zz33KCIiQkFBQUpNTdX48eP13XffadWqVZKk9PR0BQQE5DtfQECA0tPTC73e+PHjNWbMGMfr7OxsQjAAAMANoMwE4Dlz5uiee+6Rt7e3U3tcXJzj58jISNWqVUtNmzbVtm3b1LhxY0kXPkx3KcuyCmy/yMvLS15eXsVUPQAAAEqLMrEE4quvvtKePXv0wAMPXLZv48aN5eHhob1790q6sI748OHD+fodOXJEgYGBxV4rAAAASrcyEYBnz56tJk2aqGHDhpftu3PnTuXl5Sk4OFiS1LJlS2VlZWnz5s2OPt9++62ysrLUqlWrEqsZAAAApZNLl0Dk5OToxx9/dLzet2+fUlJS5Ofnp+rVq0u6sPb2o48+0iuvvJLv+P/973+Kj49X165d5e/vr127dmns2LFq1KiRWrduLUmqV6+eunTpori4OMfj0YYPH67u3bsX+gQIAAAA3LhcOgO8ZcsWNWrUSI0aNZIkjRkzRo0aNdKkSZMcfRYvXizLsjRw4MB8x3t6emr16tXq3Lmz6tSpo1GjRik6OlqJiYlyc3Nz9IuPj1dUVJSio6MVHR2tBg0aaMGCBSU/QAAAAJQ6NsuyLFcXURZkZ2fLbrcrKytLvr6+ri4HgIuEP7nC1SUUyf7nu7m6BAAocVea18rEGmAAAACguBCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAo7g0AK9fv149evRQSEiIbDabli1b5rR/yJAhstlsTluLFi2c+uTm5mrkyJHy9/dXxYoV1bNnTx06dMipT2ZmpmJjY2W322W32xUbG6vjx4+X8OgAAABQGrk0AJ88eVINGzbUzJkzC+3TpUsXpaWlObbPP//caf/o0aO1dOlSLV68WF9//bVycnLUvXt3nTt3ztFn0KBBSklJUUJCghISEpSSkqLY2NgSGxcAAABKL3dXXjwmJkYxMTF/2sfLy0tBQUEF7svKytLs2bO1YMECdezYUZK0cOFChYaGKjExUZ07d9bu3buVkJCgTZs2qXnz5pKkd999Vy1bttSePXtUp06d4h0UAAAASrVSvwZ47dq1CggIUO3atRUXF6eMjAzHvq1btyovL0/R0dGOtpCQEEVGRmrDhg2SpI0bN8putzvCryS1aNFCdrvd0acgubm5ys7OdtoAAABQ9pXqABwTE6P4+HglJSXplVdeUXJystq3b6/c3FxJUnp6ujw9PVW5cmWn4wIDA5Wenu7oExAQkO/cAQEBjj4FmTp1qmPNsN1uV2hoaDGODAAAAK7i0iUQl9O/f3/Hz5GRkWratKnCwsK0YsUK9erVq9DjLMuSzWZzvP7jz4X1udT48eM1ZswYx+vs7GxCMAAAwA2gVM8AXyo4OFhhYWHau3evJCkoKEhnzpxRZmamU7+MjAwFBgY6+hw+fDjfuY4cOeLoUxAvLy/5+vo6bQAAACj7ylQAPnr0qA4ePKjg4GBJUpMmTeTh4aFVq1Y5+qSlpSk1NVWtWrWSJLVs2VJZWVnavHmzo8+3336rrKwsRx8AAACYw6VLIHJycvTjjz86Xu/bt08pKSny8/OTn5+fpkyZot69eys4OFj79+/XU089JX9/f919992SJLvdrmHDhmns2LGqUqWK/Pz8NG7cOEVFRTmeClGvXj116dJFcXFxevvttyVJw4cPV/fu3XkCBAAAgIFcGoC3bNmidu3aOV5fXHM7ePBgvfnmm9qxY4fee+89HT9+XMHBwWrXrp0++OAD+fj4OI559dVX5e7urn79+un06dPq0KGD5s2bJzc3N0ef+Ph4jRo1yvG0iJ49e/7ps4cBAABw47JZlmW5uoiyIDs7W3a7XVlZWawHBgwW/uQKV5dQJPuf7+bqEgCgxF1pXitTa4ABAACAa0UABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFFcGoDXr1+vHj16KCQkRDabTcuWLXPsy8vL0xNPPKGoqChVrFhRISEhuu+++/Trr786naNt27ay2WxO24ABA5z6ZGZmKjY2Vna7XXa7XbGxsTp+/Ph1GCEAAABKG5cG4JMnT6phw4aaOXNmvn2nTp3Stm3bNHHiRG3btk1LlizRDz/8oJ49e+brGxcXp7S0NMf29ttvO+0fNGiQUlJSlJCQoISEBKWkpCg2NrbExgUAAIDSy92VF4+JiVFMTEyB++x2u1atWuXUNmPGDN1+++36+eefVb16dUd7hQoVFBQUVOB5du/erYSEBG3atEnNmzeXJL377rtq2bKl9uzZozp16hTTaAAAAFAWlKk1wFlZWbLZbKpUqZJTe3x8vPz9/VW/fn2NGzdOJ06ccOzbuHGj7Ha7I/xKUosWLWS327Vhw4ZCr5Wbm6vs7GynDQAAAGWfS2eAr8bvv/+uJ598UoMGDZKvr6+j/Z577lFERISCgoKUmpqq8ePH67vvvnPMHqenpysgICDf+QICApSenl7o9aZOnaqnn366+AcCAAAAlyoTATgvL08DBgzQ+fPn9cYbbzjti4uLc/wcGRmpWrVqqWnTptq2bZsaN24sSbLZbPnOaVlWge0XjR8/XmPGjHG8zs7OVmho6LUOBQAAAC5W6gNwXl6e+vXrp3379ikpKclp9rcgjRs3loeHh/bu3avGjRsrKChIhw8fztfvyJEjCgwMLPQ8Xl5e8vLyuub6AQAAULqU6jXAF8Pv3r17lZiYqCpVqlz2mJ07dyovL0/BwcGSpJYtWyorK0ubN2929Pn222+VlZWlVq1alVjtAAAAKJ1cOgOck5OjH3/80fF63759SklJkZ+fn0JCQtSnTx9t27ZNn332mc6dO+dYs+vn5ydPT0/973//U3x8vLp27Sp/f3/t2rVLY8eOVaNGjdS6dWtJUr169dSlSxfFxcU5Ho82fPhwde/enSdAAAAAGMilAXjLli1q166d4/XFNbeDBw/WlClTtHz5cknSbbfd5nTcmjVr1LZtW3l6emr16tV67bXXlJOTo9DQUHXr1k2TJ0+Wm5ubo398fLxGjRql6OhoSVLPnj0LfPYwAAAAbnwuDcBt27aVZVmF7v+zfZIUGhqqdevWXfY6fn5+Wrhw4VXXBwAAgBtPqV4DDAAAABQ3AjAAAACMUuofgwYAQEkIf3KFq0sokv3Pd3N1CUCZxwwwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARilSAK5Ro4aOHj2ar/348eOqUaPGNRcFAAAAlJQiBeD9+/fr3Llz+dpzc3P1yy+/XHNRAAAAQEm5qgC8fPlyLV++XJK0cuVKx+vly5dr6dKl+te//qXw8PArPt/69evVo0cPhYSEyGazadmyZU77LcvSlClTFBISovLly6tt27bauXOnU5/c3FyNHDlS/v7+qlixonr27KlDhw459cnMzFRsbKzsdrvsdrtiY2N1/Pjxqxk6AAAAbhDuV9P5rrvukiTZbDYNHjzYaZ+Hh4fCw8P1yiuvXPH5Tp48qYYNG2ro0KHq3bt3vv0vvviipk2bpnnz5ql27dp65pln1KlTJ+3Zs0c+Pj6SpNGjR+vTTz/V4sWLVaVKFY0dO1bdu3fX1q1b5ebmJkkaNGiQDh06pISEBEnS8OHDFRsbq08//fRqhg8AAIAbwFUF4PPnz0uSIiIilJycLH9//2u6eExMjGJiYgrcZ1mWpk+frgkTJqhXr16SpPnz5yswMFCLFi3Sgw8+qKysLM2ePVsLFixQx44dJUkLFy5UaGioEhMT1blzZ+3evVsJCQnatGmTmjdvLkl699131bJlS+3Zs0d16tS5pjEAAACgbCnSGuB9+/Zdc/i9kmukp6crOjra0ebl5aU2bdpow4YNkqStW7cqLy/PqU9ISIgiIyMdfTZu3Ci73e4Iv5LUokUL2e12R5+C5ObmKjs722kDAABA2XdVM8B/tHr1aq1evVoZGRmOmeGL5syZc82FpaenS5ICAwOd2gMDA3XgwAFHH09PT1WuXDlfn4vHp6enKyAgIN/5AwICHH0KMnXqVD399NPXNAYAAACUPkWaAX766acVHR2t1atX67ffflNmZqbTVpxsNpvTa8uy8rVd6tI+BfW/3HnGjx+vrKwsx3bw4MGrrBwAAAClUZFmgN966y3NmzdPsbGxxV2PQ1BQkKQLM7jBwcGO9oyMDMescFBQkM6cOaPMzEynWeCMjAy1atXK0efw4cP5zn/kyJF8s8t/5OXlJS8vr2IZCwAAAEqPIs0AnzlzxhEwS0pERISCgoK0atUqp+uuW7fOce0mTZrIw8PDqU9aWppSU1MdfVq2bKmsrCxt3rzZ0efbb79VVlZWiY8BAAAApU+RZoAfeOABLVq0SBMnTrymi+fk5OjHH390vN63b59SUlLk5+en6tWra/To0XruuedUq1Yt1apVS88995wqVKigQYMGSZLsdruGDRumsWPHqkqVKvLz89O4ceMUFRXleCpEvXr11KVLF8XFxentt9+WdOExaN27d+cJEAAAAAYqUgD+/fff9c477ygxMVENGjSQh4eH0/5p06Zd0Xm2bNmidu3aOV6PGTNGkjR48GDNmzdPjz/+uE6fPq0RI0YoMzNTzZs315dfful4BrAkvfrqq3J3d1e/fv10+vRpdejQQfPmzXM8A1iS4uPjNWrUKMfTInr27KmZM2cWZegAAAAo42yWZVlXe9AfQ2u+E9psSkpKuqaiSqPs7GzZ7XZlZWXJ19fX1eUAcJHwJ1e4uoQi2f98N1eXUOpwL4Ebz5XmtSLNAK9Zs6bIhQEAAACuVKQPwQEAAABlVZFmgNu1a/enz9C9EZdAAAAA4MZQpAB82223Ob3Oy8tTSkqKUlNTNXjw4OKoCwAAACgRRQrAr776aoHtU6ZMUU5OzjUVBAAAAJSkYl0DfO+992rOnDnFeUoAAACgWBVrAN64caO8vb2L85QAAABAsSrSEohevXo5vbYsS2lpadqyZcs1fzscAAAAUJKKFIDtdrvT63LlyqlOnTr65z//6fi2NQAAAKA0KlIAnjt3bnHXAQAAAFwXRQrAF23dulW7d++WzWbTrbfeqkaNGhVXXQAAAECJKFIAzsjI0IABA7R27VpVqlRJlmUpKytL7dq10+LFi1W1atXirhMAAAAoFkV6CsTIkSOVnZ2tnTt36tixY8rMzFRqaqqys7M1atSo4q4RAAAAKDZFmgFOSEhQYmKi6tWr52i79dZbNWvWLD4EBwAAgFKtSDPA58+fl4eHR752Dw8PnT9//pqLAgAAAEpKkQJw+/bt9fe//12//vqro+2XX37Ro48+qg4dOhRbcQAAAEBxK1IAnjlzpk6cOKHw8HDVrFlTt9xyiyIiInTixAnNmDGjuGsEAAAAik2R1gCHhoZq27ZtWrVqlb7//ntZlqVbb71VHTt2LO76AAAAgGJ1VTPASUlJuvXWW5WdnS1J6tSpk0aOHKlRo0apWbNmql+/vr766qsSKRQAAAAoDlcVgKdPn664uDj5+vrm22e32/Xggw9q2rRpxVYcAAAAUNyuKgB/99136tKlS6H7o6OjtXXr1msuCgAAACgpVxWADx8+XODjzy5yd3fXkSNHrrkoAAAAoKRcVQCuVq2aduzYUej+7du3Kzg4+JqLAgAAAErKVQXgrl27atKkSfr999/z7Tt9+rQmT56s7t27F1txAAAAQHG7qseg/eMf/9CSJUtUu3ZtPfLII6pTp45sNpt2796tWbNm6dy5c5owYUJJ1QoAAABcs6sKwIGBgdqwYYMeeughjR8/XpZlSZJsNps6d+6sN954Q4GBgSVSKAAAAFAcrvqLMMLCwvT5558rMzNTP/74oyzLUq1atVS5cuWSqA8AAAAoVkX6JjhJqly5spo1a1actQAAAAAl7qo+BAcAAACUdQRgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFFKfQAODw+XzWbLtz388MOSpCFDhuTb16JFC6dz5ObmauTIkfL391fFihXVs2dPHTp0yBXDAQAAgIuV+gCcnJystLQ0x7Zq1SpJUt++fR19unTp4tTn888/dzrH6NGjtXTpUi1evFhff/21cnJy1L17d507d+66jgUAAACu5+7qAi6natWqTq+ff/551axZU23atHG0eXl5KSgoqMDjs7KyNHv2bC1YsEAdO3aUJC1cuFChoaFKTExU586dS654AAAAlDqlfgb4j86cOaOFCxfq/vvvl81mc7SvXbtWAQEBql27tuLi4pSRkeHYt3XrVuXl5Sk6OtrRFhISosjISG3YsKHQa+Xm5io7O9tpAwAAQNlXpgLwsmXLdPz4cQ0ZMsTRFhMTo/j4eCUlJemVV15RcnKy2rdvr9zcXElSenq6PD09VblyZadzBQYGKj09vdBrTZ06VXa73bGFhoaWyJgAAABwfZX6JRB/NHv2bMXExCgkJMTR1r9/f8fPkZGRatq0qcLCwrRixQr16tWr0HNZluU0i3yp8ePHa8yYMY7X2dnZhGAAAIAbQJkJwAcOHFBiYqKWLFnyp/2Cg4MVFhamvXv3SpKCgoJ05swZZWZmOs0CZ2RkqFWrVoWex8vLS15eXsVTPAAAAEqNMrMEYu7cuQoICFC3bt3+tN/Ro0d18OBBBQcHS5KaNGkiDw8Px9MjJCktLU2pqal/GoABAABwYyoTM8Dnz5/X3LlzNXjwYLm7/1/JOTk5mjJlinr37q3g4GDt379fTz31lPz9/XX33XdLkux2u4YNG6axY8eqSpUq8vPz07hx4xQVFeV4KgQAAADMUSYCcGJion7++Wfdf//9Tu1ubm7asWOH3nvvPR0/flzBwcFq166dPvjgA/n4+Dj6vfrqq3J3d1e/fv10+vRpdejQQfPmzZObm9v1HgoAAABcrEwE4OjoaFmWla+9fPnyWrly5WWP9/b21owZMzRjxoySKA8AAABlSJlZAwwAAAAUBwIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjFKqA/CUKVNks9mctqCgIMd+y7I0ZcoUhYSEqHz58mrbtq127tzpdI7c3FyNHDlS/v7+qlixonr27KlDhw5d76EAAACglCjVAViS6tevr7S0NMe2Y8cOx74XX3xR06ZN08yZM5WcnKygoCB16tRJJ06ccPQZPXq0li5dqsWLF+vrr79WTk6OunfvrnPnzrliOAAAAHAxd1cXcDnu7u5Os74XWZal6dOna8KECerVq5ckaf78+QoMDNSiRYv04IMPKisrS7Nnz9aCBQvUsWNHSdLChQsVGhqqxMREde7cudDr5ubmKjc31/E6Ozu7mEcGAAAAVyj1M8B79+5VSEiIIiIiNGDAAP3000+SpH379ik9PV3R0dGOvl5eXmrTpo02bNggSdq6davy8vKc+oSEhCgyMtLRpzBTp06V3W53bKGhoSUwOgAAAFxvpToAN2/eXO+9955Wrlypd999V+np6WrVqpWOHj2q9PR0SVJgYKDTMYGBgY596enp8vT0VOXKlQvtU5jx48crKyvLsR08eLAYRwYAAABXKdVLIGJiYhw/R0VFqWXLlqpZs6bmz5+vFi1aSJJsNpvTMZZl5Wu71JX08fLykpeXVxErBwAAQGlVqmeAL1WxYkVFRUVp7969jnXBl87kZmRkOGaFg4KCdObMGWVmZhbaBwAAAGYpUwE4NzdXu3fvVnBwsCIiIhQUFKRVq1Y59p85c0br1q1Tq1atJElNmjSRh4eHU5+0tDSlpqY6+gAAAMAspXoJxLhx49SjRw9Vr15dGRkZeuaZZ5Sdna3BgwfLZrNp9OjReu6551SrVi3VqlVLzz33nCpUqKBBgwZJkux2u4YNG6axY8eqSpUq8vPz07hx4xQVFeV4KgQAAADMUqoD8KFDhzRw4ED99ttvqlq1qlq0aKFNmzYpLCxMkvT444/r9OnTGjFihDIzM9W8eXN9+eWX8vHxcZzj1Vdflbu7u/r166fTp0+rQ4cOmjdvntzc3Fw1LAAAALiQzbIsy9VFlAXZ2dmy2+3KysqSr6+vq8sB4CLhT65wdQlFsv/5bq4uodThXgI3nivNa2VqDTAAAABwrQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABjF3dUFACYIf3KFq0sokv3Pd3N1CQAAFDtmgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBS+CQ4AgBsY30QJ5McMMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUdxdXQCAG0f4kytcXUKR7H++m6tLAABcR8wAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFFKdQCeOnWqmjVrJh8fHwUEBOiuu+7Snj17nPoMGTJENpvNaWvRooVTn9zcXI0cOVL+/v6qWLGievbsqUOHDl3PoQAAAKCUKNUBeN26dXr44Ye1adMmrVq1SmfPnlV0dLROnjzp1K9Lly5KS0tzbJ9//rnT/tGjR2vp0qVavHixvv76a+Xk5Kh79+46d+7c9RwOAAAASoFS/UUYCQkJTq/nzp2rgIAAbd26VXfeeaej3cvLS0FBQQWeIysrS7Nnz9aCBQvUsWNHSdLChQsVGhqqxMREde7cueQGAAAAUEz4sqHiU6pngC+VlZUlSfLz83NqX7t2rQICAlS7dm3FxcUpIyPDsW/r1q3Ky8tTdHS0oy0kJESRkZHasGFDodfKzc1Vdna20wYAAICyr8wEYMuyNGbMGP3lL39RZGSkoz0mJkbx8fFKSkrSK6+8ouTkZLVv3165ubmSpPT0dHl6eqpy5cpO5wsMDFR6enqh15s6darsdrtjCw0NLZmBAQAA4Loq1Usg/uiRRx7R9u3b9fXXXzu19+/f3/FzZGSkmjZtqrCwMK1YsUK9evUq9HyWZclmsxW6f/z48RozZozjdXZ2NiEYAADgBlAmZoBHjhyp5cuXa82aNbr55pv/tG9wcLDCwsK0d+9eSVJQUJDOnDmjzMxMp34ZGRkKDAws9DxeXl7y9fV12gAAAFD2leoAbFmWHnnkES1ZskRJSUmKiIi47DFHjx7VwYMHFRwcLElq0qSJPDw8tGrVKkeftLQ0paamqlWrViVWOwAAAEqnUr0E4uGHH9aiRYv0ySefyMfHx7Fm1263q3z58srJydGUKVPUu3dvBQcHa//+/Xrqqafk7++vu+++29F32LBhGjt2rKpUqSI/Pz+NGzdOUVFRjqdCAAAAwBylOgC/+eabkqS2bds6tc+dO1dDhgyRm5ubduzYoffee0/Hjx9XcHCw2rVrpw8++EA+Pj6O/q+++qrc3d3Vr18/nT59Wh06dNC8efPk5uZ2PYcDAACAUqBUB2DLsv50f/ny5bVy5crLnsfb21szZszQjBkziqs0AAAAlFGleg0wAAAAUNwIwAAAADBKqV4CYTq+8hAAAKD4MQMMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKO6uLgAAUPqEP7nC1SUUyf7nu7m6BABlADPAAAAAMAoBGAAAAEYhAAMAAMAoBGAAAAAYhQAMAAAAoxCAAQAAYBQCMAAAAIxCAAYAAIBRCMAAAAAwCgEYAAAARiEAAwAAwCgEYAAAABiFAAwAAACjuLu6AJgt/MkVri6hSPY/383VJQAAgCJiBhgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhAAMAAMAofBUyAAAo08KfXOHqEopk//PdXF2CsZgBBgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMYFYDfeOMNRUREyNvbW02aNNFXX33l6pIAAABwnRkTgD/44AONHj1aEyZM0H//+1/dcccdiomJ0c8//+zq0gAAAHAdGROAp02bpmHDhumBBx5QvXr1NH36dIWGhurNN990dWkAAAC4joz4JrgzZ85o69atevLJJ53ao6OjtWHDhgKPyc3NVW5uruN1VlaWJCk7O7vkCr3E+dxT1+1axelq/oxMGKPEOEs73rP5mTBOE8YomTFOE8YomTPO4riWZVl/3tEywC+//GJJsr755hun9meffdaqXbt2gcdMnjzZksTGxsbGxsbGxlbGtoMHD/5pNjRiBvgim83m9NqyrHxtF40fP15jxoxxvD5//ryOHTumKlWqFHpMWZGdna3Q0FAdPHhQvr6+ri4H14B7eePgXt44uJc3Du5l2WNZlk6cOKGQkJA/7WdEAPb395ebm5vS09Od2jMyMhQYGFjgMV5eXvLy8nJqq1SpUkmV6BK+vr78hb5BcC9vHNzLGwf38sbBvSxb7Hb7ZfsY8SE4T09PNWnSRKtWrXJqX7VqlVq1auWiqgAAAOAKRswAS9KYMWMUGxurpk2bqmXLlnrnnXf0888/629/+5urSwMAAMB1ZEwA7t+/v44ePap//vOfSktLU2RkpD7//HOFhYW5urTrzsvLS5MnT863xANlD/fyxsG9vHFwL28c3Msbl82yLvecCAAAAODGYcQaYAAAAOAiAjAAAACMQgAGAACAUQjAAAAAMAoBGAAAAEYhABvk7NmzysvLc3UZKEY8xKVsS0tL065du1xdBorJqVOn+G8sUEYQgA2xa9cu3XPPPWrfvr2GDh2q999/39UloYhOnjypEydOKDs7WzabzdXloIh++eUXRUVF6R//+Ie2bNni6nJwjVJTUzVw4EBt2rRJubm5ri4H1+DQoUP64IMP9PHHH2v79u2uLgclhABsgB9++EGtWrWSp6enOnXqpJ9++kkvvfSShg4d6urScJV27dqlXr16qU2bNqpXr57i4+MlMRNcFv3www/KyspSVlaWZsyYoW3btjn2cT/Llp07d+rOO+/UzTffrBo1avClCWXYjh079Je//EUvv/yyHn74YU2cOFE//fSTq8tCCSAA3+Asy9J7772nTp06acGCBZo0aZK++OILDRs2TFu3blX//v1dXSKu0K5du3TnnXeqfv36euyxxzRgwAANHTpUKSkpzASXQQ0bNlTXrl3Vv39/paamatq0adq5c6ckAnBZcvLkSY0ZM0YDBgzQrFmzVK1aNX3//ff67rvvdPDgQVeXh6tw4MABxcTEaODAgVq7dq3mzp2rzZs36+jRo64uDSWAb4IzwNChQ/Xjjz/qq6++crSdPn1aixYt0qxZs9S5c2dNnTrVhRXico4dO6aBAweqbt26eu211xzt7du3V1RUlF577TVZlkUQLiPOnTunY8eO6S9/+YuSkpK0efNmTZ06Vbfddpt27typ4OBg/ec//3F1mbgCubm56tixo15//XU1aNBA3bp107Fjx/T999+rfv36euCBBzRs2DBXl4kr8Pbbb2vx4sVKSkpy/Le0W7du+utf/ypvb2+FhoaqXbt2Lq4SxcXd1QWg5FwMRI0bN9aePXv0/fffq27dupKk8uXLq2/fvvrhhx+0Zs0aZWRkKCAgwMUVozB5eXk6fvy4+vTpI0k6f/68ypUrpxo1ajhmJwi/ZUe5cuVUtWpVNWvWTKmpqbr77rvl5eWlwYMHKzc3V3Fxca4uEVfo+PHj2rNnj3777Tc99thjkqR3331XaWlpSkpK0j/+8Q/Z7XbH312UXpZl6eeff1ZKSooaNWqkZ599Vl988YXOnDmjrKwsHThwQC+88IKGDBni6lJRDFgCcQO7GIi6du2qvXv36sUXX9SJEycc+319fTV69GglJydrw4YNrioTVyAwMFALFy7UHXfcIenCDKIkVatWTeXKOf81zsnJue714epc/Lvp5uamtWvXSpKWLFmic+fOKTQ0VF999ZU2b97swgpxpQICAtShQwctX75ce/fu1aOPPqqGDRuqS5cuGjVqlDp27KjVq1fr3LlzLG0p5Tp37qygoCD169dPffr00cSJE7V06VJ9+eWX+uyzzzRgwADNnz9fR48e5V7eAJgBNkDNmjX14YcfKiYmRhUqVNCUKVPk7+8vSfL09FSjRo1UqVIl1xaJy6pVq5akC7O/Hh4eki4E4cOHDzv6TJ06VV5eXho1apTc3fnrXVpd/O1M+/bt9dNPP2nEiBH6/PPPtXXrVqWkpOixxx6Tp6enGjRoIG9vb1eXiz9hs9k0duxYtW3bVqdOndLw4cMd+26++WYFBgYqOTlZ5cqV47c0pVxERITi4+O1ZcsW7dy5UzabTX/9618lXfiHTkhIiNatW6eKFStyL28A/B/SEO3atdNHH32kvn376tdff1Xfvn3VoEEDLViwQIcOHVLNmjVdXSKuULly5RwBymazyc3NTZI0adIkPfPMM/rvf/9L+C3lLv7PMyIiQkOHDlVgYKA+++wzRUREKCIiQjabTQ0bNiT8lhFNmzbVF198oTZt2uidd95RjRo1VL9+fUkXli/Vrl1bZ8+edfzDFaVXeHi4wsPDdfz4cSUnJ+vMmTPy9PSUJB0+fFjh4eGO38ChbONDcIbZtm2bxowZo3379snd3V0eHh56//331ahRI1eXhqtwcQ3wlClTlJaWplq1aukf//iHNmzYoMaNG7u6PFyhvLw8LViwQE2bNlWDBg34IGMZt379eg0cOFA333yzoqKidObMGS1fvlxff/21IiMjXV0ersKuXbvUqlUrTZgwQUFBQUpNTdU777yj9evXKyoqytXloRgQgA2UnZ2tY8eOKScnR0FBQY7lECh7nn32WU2cOFG+vr5KTExU06ZNXV0SrtLFf8zgxrBnzx4tXLhQmzZtUq1atTRixAjCbxm1Zs0axcXFqVy5cqpWrZpee+01NWjQwNVloZgQgIEybMuWLbr99tuVmpqqW2+91dXlAPj/zp8/L0n846aMO3bsmPLy8uTl5cVnZW4wBGCgjDt58qQqVqzo6jIAACgzCMAAAAAwCr+bAQAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAHAAPPmzSuWB/nbbDYtW7bsms8DAK5EAAaAMmLIkCG66667XF0GAJR5BGAAAAAYhQAMADeAadOmKSoqShUrVlRoaKhGjBihnJycfP2WLVum2rVry9vbW506ddLBgwed9n/66adq0qSJvL29VaNGDT399NM6e/Zsgdc8c+aMHnnkEQUHB8vb21vh4eGaOnVqiYwPAIoTARgAbgDlypXT66+/rtTUVM2fP19JSUl6/PHHnfqcOnVKzz77rObPn69vvvlG2dnZGjBggGP/ypUrde+992rUqFHatWuX3n77bc2bN0/PPvtsgdd8/fXXtXz5cn344Yfas2ePFi5cqPDw8JIcJgAUC5tlWZariwAAXN6QIUN0/PjxK/oQ2kcffaSHHnpIv/32m6QLH4IbOnSoNm3apObNm0uSvv/+e9WrV0/ffvutbr/9dt15552KiYnR+PHjHedZuHChHn/8cf3666+SLnwIbunSpbrrrrs0atQo7dy5U4mJibLZbMU/YAAoIcwAA8ANYM2aNerUqZOqVasmHx8f3XfffTp69KhOnjzp6OPu7q6mTZs6XtetW1eVKlXS7t27JUlbt27VP//5T910002OLS4uTmlpaTp16lS+aw4ZMkQpKSmqU6eORo0apS+//LLkBwoAxYAADABl3IEDB9S1a1dFRkbq448/1tatWzVr1ixJUl5enlPfgmZqL7adP39eTz/9tFJSUhzbjh07tHfvXnl7e+c7rnHjxtq3b5/+9a9/6fTp0+rXr5/69OlTAiMEgOLl7uoCAADXZsuWLTp79qxeeeUVlSt3YV7jww8/zNfv7Nmz2rJli26//XZJ0p49e3T8+HHVrVtX0oVAu2fPHt1yyy1XfG1fX1/1799f/fv3V58+fdSlSxcdO3ZMfn5+xTAyACgZBGAAKEOysrKUkpLi1Fa1alWdPXtWM2bMUI8ePfTNN9/orbfeynesh4eHRo4cqddff10eHh565JFH1KJFC0cgnjRpkrp3767Q0FD17dtX5cqV0/bt27Vjxw4988wz+c736quvKjg4WLfddpvKlSunjz76SEFBQcXyhRsAUJJYAgEAZcjatWvVqFEjp23OnDmaNm2aXnjhBUVGRio+Pr7Ax5FVqFBBTzzxhAYNGqSWLVuqfPnyWrx4sWN/586d9dlnn2nVqlVq1qyZWrRooWnTpiksLKzAWm666Sa98MILatq0qZo1a6b9+/fr888/d8xCA0BpxVMgAAAAYBT+mQ4AAACjEIABAABgFAIwAAAAjEIABgAAgFEIwAAAADAKARgAAABGIQADAADAKARgAAAAGIUADAAAAKMQgAEAAGAUAjAAAACM8v8ATp3h3tD3f0gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class distribution of predictions\n",
    "\n",
    "\n",
    "filtered_df = test_df.dropna(subset=['Label'])\n",
    "label_counts = {}\n",
    "all_labels = filtered_df['Label'].str.split().explode()\n",
    "\n",
    "for label in all_labels:\n",
    "    label = int(label)\n",
    "    if label in label_counts:\n",
    "        label_counts[label] += 1\n",
    "    else:\n",
    "        label_counts[label] = 1\n",
    "\n",
    "sorted_label_counts = {k: v for k, v in sorted(label_counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_label_counts.keys(), sorted_label_counts.values())\n",
    "plt.title('Multi-label Class Distribution')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
