{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organelle image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This project aims to revolutionize protein classification through advanced image analysis techniques. The primary objective is to create a machine learning model capable of predicting the presence of specific proteins within a given image or multiple images, addressing the complexity of a multi-label classification challenge. The metric of choice for assessing model performance is the mean F1-score, ensuring precision and recall are both accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data_dir = \"./train\"\n",
    "train_csv_dir = \"./train.csv\"\n",
    "\n",
    "test_data_dir = \"./test\"\n",
    "test_csv_dir = \"./sub.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12874</td>\n",
       "      <td>1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095</td>\n",
       "      <td>2 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Label\n",
       "0  12874   1 4\n",
       "1  21466     0\n",
       "2   3610     4\n",
       "3   2095   2 4\n",
       "4  28909     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image  Label\n",
       "0  25880      0\n",
       "1   7810      0\n",
       "2  23748      0\n",
       "3  24621      0\n",
       "4  30169      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the csv files containing the train labels and test ID's in dataframes:\n",
    "train_df = pd.read_csv(train_csv_dir)\n",
    "test_df = pd.read_csv(test_csv_dir)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dictionary\n",
    "labels = {\n",
    "    0: \"Mitochondria\",\n",
    "    1: \"Nuclear bodies\",\n",
    "    2: \"Nucleoli\",\n",
    "    3: \"Golgi apparatus\",\n",
    "    4: \"Nucleoplasm\",\n",
    "    5: \"Nucleoli fibrillar center\",\n",
    "    6: \"Cytosol\",\n",
    "    7: \"Plasma membrane\",\n",
    "    8: \"Centrosome\",\n",
    "    9: \"Nuclear speckles\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a multi-label classification problem, images can have more than 1 label. In order to transform the labels to a tensor that can be used for training, we can encode them to the format of a tensor, using a one-hot-encoding.\n",
    "def encode_label(label: str):\n",
    "    # create tensor of length 10 for the one-hot-ecoding\n",
    "    target = torch.zeros(10)\n",
    "    # now iterate over the classes in the string and set the respective 0's to 1's\n",
    "    for l in str(label).split(\" \"):\n",
    "        target[int(l)] = 1.0\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to decode the encoded labels back to its original format\n",
    "\n",
    "\n",
    "def decode_target(\n",
    "    target: torch.Tensor, text_labels: bool = False, threshold: float = 0.5\n",
    "):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if x >= threshold:\n",
    "            if text_labels:\n",
    "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 128\n",
      "height: 128\n"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "image_path = 'train/0.png'\n",
    "image = Image.open(image_path)\n",
    "width, height = image.size\n",
    "print(f'width: {width}\\nheight: {height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a PyTorchDataset that will ease the training process and can be used later for the DataLoader:\n",
    "\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_dir='./train', transform=None, mode='train'):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode  # 'train' or 'test'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            img_name = os.path.join(self.data_dir, str(self.data.iloc[idx, 0]) + '.png')\n",
    "            image = Image.open(img_name)\n",
    "            label = encode_label(self.data.iloc[idx, 1])\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "        elif self.mode == 'test':\n",
    "            img_name = os.path.join(self.data_dir, str(self.data.iloc[idx, 0]) + '.png')\n",
    "            image = Image.open(img_name)\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, self.data.iloc[idx, 0]  # Return image name for test mode\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Use 'train' or 'test'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProteinCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            32 * 32 * 32, 256\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            256, 10\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(\n",
    "            -1, 32 * 32 * 32\n",
    "        )\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128 pixels if still needed\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transformations as needed (e.g., normalization, data augmentation)\n",
    "])\n",
    "\n",
    "train_size = int(0.8 * len(train_df))\n",
    "val_size = len(train_df) - train_size\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(train_df, test_size=val_size)\n",
    "\n",
    "train_loader = DataLoader(ProteinDataset(train_dataset, transform=transforms_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(ProteinDataset(val_dataset, transform=transforms_train), batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProteinCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.3553027282287548, Validation Loss: 0.3357306746477933\n",
      "Epoch 2/10, Training Loss: 0.32751903948071714, Validation Loss: 0.32520058198073476\n",
      "Epoch 3/10, Training Loss: 0.3094104642217809, Validation Loss: 0.32895459541954947\n",
      "Epoch 4/10, Training Loss: 0.26700921948854023, Validation Loss: 0.35286656882345063\n",
      "Epoch 5/10, Training Loss: 0.18574697886194502, Validation Loss: 0.4282612256782571\n",
      "Epoch 6/10, Training Loss: 0.09338631022286105, Validation Loss: 0.5835017174789586\n",
      "Epoch 7/10, Training Loss: 0.03867001649379343, Validation Loss: 0.8103485703468323\n",
      "Epoch 8/10, Training Loss: 0.01986734572096498, Validation Loss: 0.9303343246892556\n",
      "Epoch 9/10, Training Loss: 0.012905308548602964, Validation Loss: 1.1322299579984134\n",
      "Epoch 10/10, Training Loss: 0.010490603451526349, Validation Loss: 1.1741705100560926\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.8558479532163743\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "threshold = 0.5  # Define a threshold for prediction\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold to convert probabilities to binary predictions\n",
    "        predicted = (outputs > threshold).float()\n",
    "        \n",
    "        total += labels.size(0) * labels.size(1)  # Total number of elements in the batch\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on validation set: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the test set\n",
    "\n",
    "test_dataset = ProteinDataset(test_df, data_dir=test_data_dir, transform=transforms_train, mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test images\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, img_names in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold for binary predictions\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs > threshold).squeeze().cpu().numpy().astype(int)\n",
    "        \n",
    "        # Convert predictions to label format\n",
    "        predicted_labels = \" \".join([str(i) for i in np.where(predicted == 1)[0]])\n",
    "\n",
    "        # Append image names and predicted labels to list\n",
    "        predictions.append((img_names[0].item(), predicted_labels))\n",
    "\n",
    "# Write predictions to sub.csv\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"Image\", \"Label\"])\n",
    "submission_df.to_csv(\"sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
