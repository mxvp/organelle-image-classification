{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organelle image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torchinfo import summary\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This project aims to revolutionize protein classification through advanced image analysis techniques. The primary objective is to create a machine learning model capable of predicting the presence of specific proteins within a given image or multiple images, addressing the complexity of a multi-label classification challenge. The metric of choice for assessing model performance is the mean F1-score, ensuring precision and recall are both accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data_dir = \"./train\"\n",
    "train_csv = \"./train.csv\"\n",
    "\n",
    "test_data_dir = \"./test\"\n",
    "test_csv = \"./sub.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file containing the train labels\n",
    "train_df = pd.read_csv(train_csv)\n",
    "test_df = pd.read_csv(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dictionary\n",
    "labels = {\n",
    "    0: \"Mitochondria\",\n",
    "    1: \"Nuclear bodies\",\n",
    "    2: \"Nucleoli\",\n",
    "    3: \"Golgi apparatus\",\n",
    "    4: \"Nucleoplasm\",\n",
    "    5: \"Nucleoli fibrillar center\",\n",
    "    6: \"Cytosol\",\n",
    "    7: \"Plasma membrane\",\n",
    "    8: \"Centrosome\",\n",
    "    9: \"Nuclear speckles\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12874</td>\n",
       "      <td>1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095</td>\n",
       "      <td>2 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Label\n",
       "0  12874   1 4\n",
       "1  21466     0\n",
       "2   3610     4\n",
       "3   2095   2 4\n",
       "4  28909     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check class distribution\n",
    "\n",
    "label_counts = {}\n",
    "for labels in train_df['Label']:\n",
    "    label_list = labels.split()\n",
    "    for label in label_list:\n",
    "        if label in label_counts:\n",
    "            label_counts[label] += 1\n",
    "        else:\n",
    "            label_counts[label] = 1\n",
    "\n",
    "\n",
    "sorted_label_counts = {k: v for k, v in sorted(label_counts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sorted_label_counts.keys(), sorted_label_counts.values())\n",
    "plt.title('Multi-label Class Distribution')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is noticable class imbalance, 4 and 6 (Golgi apparatus, Nucleoplasm) have a much larger occurrence than the other classes.\n",
    "\n",
    "Weights will be calculated and a weighted loss function will be used that assigns higher weights to minority class samples during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.3986194477791116, 1: 1.6294405594405594, 2: 1.1506666666666667, 3: 1.4936538461538462, 4: 0.3203767358724048, 5: 2.7125727590221187, 6: 0.5094228246611281, 7: 1.1251086431675519, 8: 2.787200956937799, 9: 2.3139026812313803}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Assuming 'train_df' contains your training dataset and 'Label' is the column name for the labels\n",
    "class_labels = train_df['Label'].astype(str)  # Convert labels to strings\n",
    "\n",
    "# Extract unique labels from the dataset\n",
    "unique_labels = set()\n",
    "for labels in class_labels:\n",
    "    unique_labels.update(labels.split())\n",
    "\n",
    "# Sort the unique labels to maintain a consistent order\n",
    "unique_labels = sorted(list(unique_labels))\n",
    "\n",
    "# Create a list of lists to hold labels for each sample\n",
    "labels_per_sample = [label.split() for label in class_labels]\n",
    "\n",
    "# Flatten the list of lists into a single list to calculate class weights\n",
    "flat_labels = []\n",
    "for labels in labels_per_sample:\n",
    "    flat_labels.extend(labels)\n",
    "\n",
    "# Calculate class weights based on occurrences\n",
    "class_weights = compute_class_weight('balanced', classes=unique_labels, y=flat_labels)\n",
    "weights_dict = {i:class_weights[i] for i in range(10)}\n",
    "print(\"Class weights:\", weights_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, more abundant classes 4 and 6 now carry lower weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Information:\n",
      "Image Size: (128, 128)\n",
      "Image Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "# Explore image characteristics\n",
    "sample_image = Image.open('./train/0.png')\n",
    "\n",
    "print(\"Sample Image Information:\")\n",
    "print(f\"Image Size: {sample_image.size}\")\n",
    "print(f\"Image Mode: {sample_image.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing labels: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_labels = train_df['Label'].isnull().sum()\n",
    "print(\"Number of missing labels:\", missing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a multi-label classification problem, images can have more than 1 label. In order to transform the labels to a tensor that can be used for training, we can encode them to the format of a tensor, using a one-hot-encoding.\n",
    "def encode_label(label: str):\n",
    "    # create tensor of length 10 for the one-hot-ecoding\n",
    "    target = torch.zeros(10)\n",
    "    # now iterate over the classes in the string and set the respective 0's to 1's\n",
    "    for l in str(label).split(\" \"):\n",
    "        target[int(l)] = 1.0\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to decode the encoded labels back to its original format\n",
    "\n",
    "\n",
    "def decode_target(\n",
    "    target: torch.Tensor, text_labels: bool = False, threshold: float = 0.5\n",
    "):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if x >= threshold:\n",
    "            if text_labels:\n",
    "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per channel: [0.07819786874680719, 0.05209000149719703, 0.05402339364832606]\n",
      "Standard deviation per channel: [0.11591775167397261, 0.07654528936568694, 0.13421668103375917]\n"
     ]
    }
   ],
   "source": [
    "# To normalize the data we need to calculate the means and stdevs per channel for the images\n",
    "# Initialize lists to store channel-wise mean and standard deviation\n",
    "mean_per_channel = [0.0, 0.0, 0.0]\n",
    "std_per_channel = [0.0, 0.0, 0.0]\n",
    "\n",
    "# Iterate over all images in the dataset directory\n",
    "count = 0\n",
    "for filename in os.listdir(train_data_dir):\n",
    "    img = Image.open(os.path.join(train_data_dir, filename))\n",
    "    img = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    \n",
    "    # Calculate per-channel mean\n",
    "    mean_per_channel[0] += np.mean(img[:, :, 0])\n",
    "    mean_per_channel[1] += np.mean(img[:, :, 1])\n",
    "    mean_per_channel[2] += np.mean(img[:, :, 2])\n",
    "    \n",
    "    # Calculate per-channel standard deviation\n",
    "    std_per_channel[0] += np.std(img[:, :, 0])\n",
    "    std_per_channel[1] += np.std(img[:, :, 1])\n",
    "    std_per_channel[2] += np.std(img[:, :, 2])\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "# Calculate the mean and standard deviation across all images\n",
    "total_images = len(os.listdir(train_data_dir))\n",
    "mean_per_channel = [m / total_images for m in mean_per_channel]\n",
    "std_per_channel = [s / total_images for s in std_per_channel]\n",
    "\n",
    "print(\"Mean per channel:\", mean_per_channel)\n",
    "print(\"Standard deviation per channel:\", std_per_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not dealing with everyday images but fluorescence microscopy. In these images, the RGB values behave different than regular. We will normalize the values based on the means and stdevs per channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a PyTorchDataset that will ease the training process and can be used later for the DataLoader:\n",
    "\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, dataframe, data_dir='./train', transform=None, mode='train'):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode  # 'train' or 'test'\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            img_name = os.path.join(self.data_dir, str(self.data.iloc[idx, 0]) + '.png')\n",
    "            image = Image.open(img_name)\n",
    "            label = encode_label(self.data.iloc[idx, 1])\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "        elif self.mode == 'test':\n",
    "            img_name = os.path.join(self.data_dir, str(self.data.iloc[idx, 0]) + '.png')\n",
    "            image = Image.open(img_name)\n",
    "\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, self.data.iloc[idx, 0]  # Return image name for test mode\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Use 'train' or 'test'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProteinCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "        self.fc1 = nn.Linear(\n",
    "            32 * 32 * 32, 256\n",
    "        )\n",
    "        self.fc2 = nn.Linear(\n",
    "            256, 10\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(\n",
    "            -1, 32 * 32 * 32\n",
    "        )\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Resize images to 128x128 pixels if still needed\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_per_channel, std=std_per_channel)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rotations and horizontal/vertical flips don't affect performance as these histology is not fixated in a certain orientation before imaging. All organelles are represented in a random rotation already.\n",
    "- Cropping is unnecesary as the images are focused on the organelles of interest. There is no background noise to remove.\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(0.8 * len(train_df))\n",
    "val_size = len(train_df) - train_size\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(train_df, test_size=val_size)\n",
    "\n",
    "train_loader = DataLoader(ProteinDataset(train_dataset, transform=transforms_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(ProteinDataset(val_dataset, transform=transforms_train), batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProteinCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class_weights dictionary to a tensor\n",
    "class_weights_tensor = torch.tensor([class_weights[i] for i in range(len(class_weights))], dtype=torch.float)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(weight=class_weights_tensor) # take into account the class_weights to battle the class imbalance\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.45402030077847566, Validation Loss: 0.4295280173267286\n",
      "Epoch 2/10, Training Loss: 0.3987523685802113, Validation Loss: 0.4376473389949995\n",
      "Epoch 3/10, Training Loss: 0.28332568461244756, Validation Loss: 0.49259686531479824\n",
      "Epoch 4/10, Training Loss: 0.11809674561410756, Validation Loss: 0.7169362739803865\n",
      "Epoch 5/10, Training Loss: 0.04198456878302159, Validation Loss: 1.023675912434293\n",
      "Epoch 6/10, Training Loss: 0.020543378624194242, Validation Loss: 1.140686357144228\n",
      "Epoch 7/10, Training Loss: 0.01450223003864869, Validation Loss: 1.2843260156739618\n",
      "Epoch 8/10, Training Loss: 0.012611895419548375, Validation Loss: 1.4381994199507016\n",
      "Epoch 9/10, Training Loss: 0.012138812985972731, Validation Loss: 1.4444149038226335\n",
      "Epoch 10/10, Training Loss: 0.017792376396911485, Validation Loss: 1.4388187085230326\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels.float()).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {running_loss / len(train_loader)}, Validation Loss: {val_loss / len(val_loader)}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.853183885640026\n",
      "Precision for each label: [0.48447205 0.13207547 0.2892562  0.23529412 0.73029772 0.25581395\n",
      " 0.53545586 0.44850498 0.18518519 0.23148148]\n",
      "Recall for each label: [0.21910112 0.07835821 0.16786571 0.06514658 0.57716263 0.06790123\n",
      " 0.40838852 0.32451923 0.12048193 0.12254902]\n",
      "F1-score for each label: [0.30174081 0.09836066 0.2124431  0.10204082 0.64476227 0.10731707\n",
      " 0.46336882 0.37656904 0.1459854  0.16025641]\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "threshold = 0.5  # Define a threshold for prediction\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold to convert probabilities to binary predictions\n",
    "        predicted = (outputs > threshold).float()\n",
    "        \n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "        total += labels.size(0) * labels.size(1)  # Total number of elements in the batch\n",
    "        correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on validation set: {accuracy}\")\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each label separately\n",
    "precision = precision_score(true_labels, predicted_labels, average=None)\n",
    "recall = recall_score(true_labels, predicted_labels, average=None)\n",
    "f1 = f1_score(true_labels, predicted_labels, average=None)\n",
    "\n",
    "# Print or use the calculated scores as needed\n",
    "print(\"Precision for each label:\", precision)\n",
    "print(\"Recall for each label:\", recall)\n",
    "print(\"F1-score for each label:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the test set\n",
    "\n",
    "test_dataset = ProteinDataset(test_df, data_dir=test_data_dir, transform=transforms_train, mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the test images\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, img_names in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Apply threshold for binary predictions\n",
    "        threshold = 0.5\n",
    "        predicted = (outputs > threshold).squeeze().cpu().numpy().astype(int)\n",
    "        \n",
    "        # Convert predictions to label format\n",
    "        predicted_labels = \" \".join([str(i) for i in np.where(predicted == 1)[0]])\n",
    "\n",
    "        # Append image names and predicted labels to list\n",
    "        predictions.append((img_names[0].item(), predicted_labels))\n",
    "\n",
    "# Write predictions to sub.csv\n",
    "submission_df = pd.DataFrame(predictions, columns=[\"Image\", \"Label\"])\n",
    "submission_df.to_csv(\"sub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
