{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organelle image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This project aims to revolutionize protein classification through advanced image analysis techniques. The primary objective is to create a machine learning model capable of predicting the presence of specific proteins within a given image or multiple images, addressing the complexity of a multi-label classification challenge. The metric of choice for assessing model performance is the mean F1-score, ensuring precision and recall are both accounted for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data_dir = './train'\n",
    "train_csv_dir = './train.csv'\n",
    "\n",
    "test_data_dir = './test'\n",
    "test_csv_dir = './submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12874</td>\n",
       "      <td>1 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3610</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2095</td>\n",
       "      <td>2 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image Label\n",
       "0  12874   1 4\n",
       "1  21466     0\n",
       "2   3610     4\n",
       "3   2095   2 4\n",
       "4  28909     4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23748</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Image  Label\n",
       "0  25880      0\n",
       "1   7810      0\n",
       "2  23748      0\n",
       "3  24621      0\n",
       "4  30169      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the csv files containing the train labels and test ID's in dataframes:\n",
    "train_df = pd.read_csv(train_csv_dir)\n",
    "test_df = pd.read_csv(test_csv_dir)\n",
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dictionary\n",
    "labels = {\n",
    "    0: 'Mitochondria',\n",
    "    1: 'Nuclear bodies',\n",
    "    2: 'Nucleoli',\n",
    "    3: 'Golgi apparatus',\n",
    "    4: 'Nucleoplasm',\n",
    "    5: 'Nucleoli fibrillar center',\n",
    "    6: 'Cytosol',\n",
    "    7: 'Plasma membrane',\n",
    "    8: 'Centrosome',\n",
    "    9: 'Nuclear speckles'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a multi-label classification problem, images can have more than 1 label. In order to transform the labels to a tensor that can be used for training, we can encode them to the format of a tensor, using a one-hot-encoding.\n",
    "def encode_label(label: str):\n",
    "    # create tensor of length 10 for the one-hot-ecoding\n",
    "    target = torch.zeros(10)\n",
    "    # now iterate over the classes in the string and set the respective 0's to 1's\n",
    "    for l in str(label).split(' '):\n",
    "        target[int(l)] =1. \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to decode the encoded labels back to its original format\n",
    "\n",
    "def decode_target(target: torch.Tensor, text_labels: bool = False, threshold: float = 0.5):\n",
    "    result = []\n",
    "    for i, x in enumerate(target):\n",
    "        if (x >= threshold):\n",
    "            if text_labels:\n",
    "                result.append(labels[i] + \"(\" + str(i) + \")\")\n",
    "            else:\n",
    "                result.append(str(i))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create a PyTorchDataset that will ease the training process and can be used later for the DataLoader:\n",
    "\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, train_labels, transform=None):\n",
    "        self.data = train_labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.data.iloc[idx, 0])  # Get the image path\n",
    "        image = Image.open(img_name)  # Open the image\n",
    "        \n",
    "        # Apply transformations if specified\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = encode_label(self.data.iloc[idx, 1])  # Encode labels using the function you defined\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your CNN model for protein classification\n",
    "class ProteinCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ProteinCNN, self).__init__()\n",
    "        # Define the layers of your CNN\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 256)  # Update input size based on your image dimensions\n",
    "        self.fc2 = nn.Linear(256, 10)  # 10 output classes for multi-label classification\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Implement the forward pass of your CNN\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 56 * 56)  # Reshape based on your image dimensions after convolutions\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# Initialize your CNN model\n",
    "model = ProteinCNN()\n",
    "\n",
    "# Set up transforms for training and validation data\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to required dimensions\n",
    "    transforms.ToTensor(),\n",
    "    # Add more transformations as needed (e.g., normalization, data augmentation)\n",
    "])\n",
    "\n",
    "# Create instances of ProteinDataset for train and validation sets\n",
    "train_dataset = ProteinDataset(train_csv_dir, train_data_dir, transform=transforms_train)\n",
    "val_dataset = ProteinDataset(val_csv_dir, val_data_dir, transform=transforms_train)\n",
    "\n",
    "# Define dataloaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Update with appropriate loss function for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Update with appropriate optimizer and learning rate\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data  # Get inputs and labels from the dataloader\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Print statistics after each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "print('Finished Training')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_course_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
